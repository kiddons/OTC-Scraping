from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import Select, WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
import csv
import time

# --- CONFIG ---
SEARCH_TERM = "PARACAP PARACETAMOL 500MG TABLET"
CSV_FILENAME = "quest3plus_pmo2_data.csv"

# --- SETUP SELENIUM ---
options = webdriver.ChromeOptions()
# options.add_argument("--headless")  # Enable for background scraping
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
driver.get("https://quest3plus.bpfk.gov.my/pmo2/index.php")

# --- WAIT AND SELECT SEARCH MODE ---
WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, "searchBy")))
select = Select(driver.find_element(By.ID, "searchBy"))
select.select_by_value("1")  # 1 = Product Name

# --- ENTER SEARCH TERM SAFELY ---
search_box = WebDriverWait(driver, 10).until(
    EC.element_to_be_clickable((By.ID, "searchTxt"))
)
search_box.click()
search_box.clear()
search_box.send_keys(SEARCH_TERM)

# --- SUBMIT SEARCH ---
driver.find_element(By.CSS_SELECTOR, "button.btn-primary").click()

# --- WAIT FOR RESULTS TABLE ---
WebDriverWait(driver, 10).until(
    EC.presence_of_element_located((By.CSS_SELECTOR, "#example tbody tr"))
)
time.sleep(2)

# --- SCRAPE RESULTS ---
rows = driver.find_elements(By.CSS_SELECTOR, "#searchTable tbody tr")
results = []

for row in rows:
    cols = row.find_elements(By.TAG_NAME, "td")
    if len(cols) >= 4:
        # Updated order based on new structure
        reg_no = cols[1].text.strip()
        product_name = cols[2].text.strip()
        holder = cols[3].text.strip()

        # Click the <a> element to trigger detail modal
        try:
            detail_link = cols[1].find_element(By.TAG_NAME, "a")  # second column = reg_no
            detail_link.click()
            time.sleep(2)
        except:
            print(f"‚ùå Could not click detail link for {reg_no}")
            continue

        # Extract detail from modal
        try:
            detail_box = WebDriverWait(driver, 5).until(
                EC.presence_of_element_located((By.ID, "product_detail"))
            )
            detail_text = detail_box.text.strip()
        except:
            detail_text = "No detail found"

        results.append([SEARCH_TERM, reg_no, product_name, holder, detail_text])
        print(f"‚úÖ {product_name} | {reg_no}\nüìÑ Detail: {detail_text[:100]}...\n")

driver.quit()

# --- SAVE TO CSV ---
with open(CSV_FILENAME, "w", newline='', encoding='utf-8') as f:
    writer = csv.writer(f)
    writer.writerow(["Search Term", "Product Name", "Registration Number", "Active Ingredient", "Detail Info"])
    writer.writerows(results)

print(f"\n‚úÖ Scraping complete. Data saved to: {CSV_FILENAME}")
